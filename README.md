# Efficient-Domain-Specific-Fine-Tuning-of-Open-Source-Llama-3-LLM
 Llama3-Finetune-PoC demonstrates efficient fine-tuning of the Llama 3 model on domain-specific datasets using PEFT techniques like LoRA and QLoRA. It optimizes resource usage with free Kaggle notebooks (2 T4 GPUs) and scales to cloud platforms like AWS SageMaker or on-premises setups.
